{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Models\n",
    "### Define constants\n",
    "Define the timesteps for the recurrent neural network. The timesteps is equal the number of pitches in the pitching sequence that you want the AI to analyze at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTEPS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent neural network\n",
    "The recurrent neural network used in this project is a simple [long short-term memory (LSTM)](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(256, return_sequences=False, input_shape=(TIMESTEPS, 21)))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure checkpoints\n",
    "We will use TensorFlow's [ModelCheckpoint](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) to save the weights of the model at each epoch so that we select the weights from the best epoch to use for the final model once training is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_filepath = 'pitch_checkpoints/cp-{epoch:04d}.ckpt'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=cp_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Each plate appearance by the opponent has it's own csv associated with it which contains the pitching information against the oponent. For example, when a new oponent steps up to the plate, a new csv will be created and will record data against that batter until that batter gets a hit or get out. The csv is formatted as `outcome,pitch_type,pitch_direction,strikes,balls,batter_handedness`. The `outcome` of the pitch is treated as its label, and the rest of the fields are treated as the input data for the model. All of the input fields will be converted to be [one hot encoded](https://en.wikipedia.org/wiki/One-hot). The first field of the one hot encoding will represent blank data. This is because the AI will consider the last n amount of pitches against a batter, where n is defined by `TIMESTEPS`. However, when throwing the first pitch against a new batter, there will be no previous pitch data to look at, so we need a way to represent this as being empty. So the one hot encoding for the `pitch_type` field will be like `[empty, fastball, screwball, curveball, splitter]`. A curveball pitch in this case would be represented as `[0, 0, 0, 1, 0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# variables for converting from label encoding to one hot encoding\npitch_types = {\n    'fastball': 1,\n    'screwball': 2,\n    'curveball': 3,\n    'splitter': 4\n}\n\nhands = {\n    'left': 1,\n    'right': 2\n}\n\ndirections = {\n    'left': 1,\n    'center': 2,\n    'right': 3\n}\n\nCSV_DIR = '../data/examples/pitching/csvs_pitches/'\ncsv_paths = glob.glob(f'{CSV_DIR}*.csv')\nrandom.shuffle(csv_paths)\n\ndata = []\nlabels = []\n\n# re ad each csv line by line\nfor csv_path in csv_paths:\n    with open(csv_path, newline='') as csv_file:\n        reader = csv.reader(csv_file, delimiter=',')\n        # initialize the pitch sequence represent all empty data\n        sequence = []\n        for i in range(TIMESTEPS):\n            hand = [1, 0, 0]\n            pitch_type = [1, 0, 0, 0, 0]\n            direction = [1, 0, 0, 0]\n            strikes = [1, 0, 0, 0]\n            balls = [1, 0, 0, 0, 0]\n            pitch = [hand, pitch_type, direction, strikes, balls]\n            pitch = [item for sublist in pitch for item in sublist]\n            sequence.append(np.array(pitch))\n        \n        # one hot encoding\n        for row in reader:\n            hand = [0, 0, 0]\n            hand[hands[row[5]]] = 1\n            \n            pitch_type = [0, 0, 0, 0, 0]\n            pitch_type[pitch_types[row[1]]] = 1\n            \n            direction = [0, 0, 0, 0]\n            direction[directions[row[2]]] = 1\n            \n            strikes = [0, 0, 0, 0]\n            strikes[int(row[3])+1] = 1\n            \n            balls = [0, 0, 0, 0, 0]\n            balls[int(row[4])+1] = 1\n            \n            pitch = [hand, pitch_type, direction, strikes, balls]\n            pitch = [item for sublist in pitch for item in sublist]\n            \n            # delete first pitch in the current sequence and append the new pitch to the sequence\n            del sequence[0]\n            sequence.append(np.array(pitch))\n            \n            data.append(np.array(sequence))\n            labels.append(float(row[0]))           \n\ndata = np.array(data)\nlabels = np.array(labels)\n\nprint(data.shape)\nprint(labels.shape)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "Train the model on the data collected. You can adjust the `BATCH_SIZE`, `EPOCHS`, and `VALIDATION_SPLIT` paramaters as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 20\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "history = model.fit(\n",
    "    x=data,\n",
    "    y=labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    callbacks=[model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model\n",
    "Evaluate the loss of the model to determine the best checkpoint to load the weights from. The lower the loss, the better the model should be at correctly predicting the outcome of a given pitch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a list of loss results on training and validation data\n",
    "# sets for each training epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "print(np.argmin(np.array(val_loss)))\n",
    "\n",
    "# Get range of epochs\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "# Plot training and validation loss per epoch\n",
    "plt.plot(epochs_range, loss, label='Training')\n",
    "plt.plot(epochs_range, val_loss, label='Validation')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "Set the `best_cp` variable to the epoch that had the best metrics and save the model as an [HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cp = 18\n",
    "best_cp_filepath = cp_filepath.format(epoch=best_cp)\n",
    "model.load_weights(best_cp_filepath)\n",
    "model.save('pitch_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "In order to use the model for inference and selecting the best pitch you will need to predict the output for each pitch for the given game state, and select the one which the model predicts to have the highest outcome. Here is an example on some dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the sequence to represent empty data\n",
    "sequence = []\n",
    "for i in range(TIMESTEPS-1):\n",
    "    sequence.append([1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0])\n",
    "\n",
    "# test game state data\n",
    "hand = [0, 0, 1]\n",
    "strikes = [0, 1, 0, 0]\n",
    "balls = [0, 1, 0, 0, 0]\n",
    "\n",
    "best_reward = -1000\n",
    "best_pitch = ''\n",
    "# predict outcome for each type of pitch\n",
    "for direction in ['left', 'center', 'right']:\n",
    "    for pitch_type in ['fastball', 'screwball', 'curveball', 'splitter']:\n",
    "        pitch_type_arr = [0, 0, 0, 0, 0]\n",
    "        pitch_type_arr[pitch_types[pitch_type]] = 1\n",
    "\n",
    "        direction_arr = [0, 0, 0, 0]\n",
    "        direction_arr[directions[direction]] = 1\n",
    "\n",
    "        pitch = [hand, pitch_type_arr, direction_arr, strikes, balls]\n",
    "        pitch = [item for sublist in pitch for item in sublist]\n",
    "        \n",
    "        cur_sequence = list(sequence)\n",
    "        cur_sequence.append(np.array(pitch))\n",
    "        \n",
    "        test_data = np.array([cur_sequence])\n",
    "        prediction = model(test_data).numpy()[0][0]\n",
    "        \n",
    "        if prediction > best_reward:\n",
    "            best_reward = prediction\n",
    "            best_pitch = f'{direction} {pitch_type}: {prediction}'\n",
    "        \n",
    "        print(f'{direction} {pitch_type}: {prediction}')\n",
    "\n",
    "print('---------------------')\n",
    "print(f'Best pitch: {best_pitch}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}